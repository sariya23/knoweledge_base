## Поиск по сетке
При поиске гиперпараметров по методу поиск по сетке мы просто обучаем модель с множеством параметров. Для поиска по сетке в sklearn есть класс `GridSearchCV`
```python
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV

pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))
param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
param_grid = [
    {
        "svc__C": param_range,
        "svc__kernel": ["linear"],
    },
    {
        "svc__C": param_range,
        "svc__gamma": param_range,
        "svc__kernel": ["rbf"],
    }
]
gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring="accuracy", cv=10, refit=True, n_jobs=-1)
gs = gs.fit(features_train, labels_train)
print(gs.best_score_)  # np.float64(0.9779710144927536)
print(gs.best_params_)  # {'svc__C': 1000.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf'}

clf = gs.best_estimator_
clf.score(features_val, labels_val)
```
В словаре нужно добавлять приписку "название шага пайплайна__", чтобы применять параметры только к нужному шагу
Подберем наилучшие параметры для SVM. В `param_grid` мы указываем комбинации, которые нужно обучить. Далее создаем инстанс `GridSearchCV`, куда передаем:
- `estimator` - сама модель
- `param_grid` - сетка поиска
- `scoring` - по какой метрике выбирать лучшую модель
- `cv` - кол-во фолдов в кросс валидации
- `refit` - обучить ли наилучшую модель
- `n_jobs` - кол-во ядер
Внутри себя класс реализует кросс валидацию. После того, как поиск завершен, мы можем сразу использовать лучшую модель через `best_estimator_`
## Рандомизированный поиск
При рандомнном поиске мы задаем диапазон значений
```python
import pandas as pd
import numpy as np
import scipy.stats
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC

param_range = scipy.stats.loguniform(0.0001, 1000.0)
pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))
rs = RandomizedSearchCV(estimator=pipe_svc, param_distributions=param_grid, scoring="accuracy", refit=True, n_iter=20, cv=10, n_jobs=-1)
rs = rs.fit(features_train, labels_train)
```
Такой поиск лучше в том случае, если нет уверенности в том, что оценка параметров при жестком поиске та самая
## Метод последовательного деления пополам
```python
from sklearn.model_selection import HavingRandomSearchCV

hs = HavingRandomSearchCV(
	pipe,
	param_distribution=param_grid,
	n_candidates="exhaust",
	resource="n_samples",
	factor=1.5,
	n_jobs=-1
)
hs = hs.fit(feature_train, labels_train)
```
## Вложенная кросс-валидация
Делаем так:
```python
param_range = [...]
param_grid = [
	{
		"svc__C": param_range,
		"svc__kernel": ["linear"],
	},
	{
		"svc__C": param_range,
		"svc__gamme": param_range,
		"svc__kernel": ["rbf"]
	}
]
gs = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring="accuracy", cv=2)
scores = cross_val_score(gs, features_train, labels_train, scoring="accuracy", cv=5)
```