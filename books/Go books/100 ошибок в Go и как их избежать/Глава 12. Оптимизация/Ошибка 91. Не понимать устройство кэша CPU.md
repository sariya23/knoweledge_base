[[100 ошибок в Go и как их избежать]]

Перед этой главной лучше посмотреть видосы Alek OS:
- Как устроен CPU - https://youtu.be/k9wK2FThEsk?si=PlwYZlI-JeebR_2y
- Как устроен кэш CPU - https://youtu.be/7n_8cOBpQrg?si=747MtkrLut1Kf61W
Но там тоже капец...

## Архитектура CPU
У современных процессоров есть 3 уровня кэша:
- L1: 64Кбайт
- L2: 256 Кбайт
- L3: 4Мбай
С ростом памяти увеличивается и скорость доступа к этому кэшу
![[Pasted image 20240928131031.png]]
Кэши 1 и 2 уровней располагаются на самом кристалле процессора. Кэш первого уровня разделен на D и L, на кэш под инструкции и под данные соответственно.
### Кэш-линия
Зачем нужна кэш-линия? При доступе к какому-то месту в памяти после этого может произойти одно из следующих событий:
- К этому же месту будет сделано снова какое-то обращение
- Будет сделано обращение к ближним ячейкам
Первый вариант относится к *временной локализации*, а второй - к *пространственной*. Обе - части *принципа локальности ссылки*
Рассмотрим функцию, которая считает сумма среза `int64`
```go
func Sum(s []int64) int64 {
    var total int64
    l := len(s)
    for i := 0; i < l; i += 2 {
        total += s[i]
    }
    return total
}
```
В этом примере принцип *временной* локальности применяется к нескольким переменным: `i`, `l`, `total`. Принцип *пространственной* локальности применяется к инструкциям кода и к срезу `s`. 
Временная локальность - одна из причин зачем нужен кэш. Чтобы ускорять доступ к одним и тем же переменным. Но из-за *пространственной* локальности CPU копирует из ОЗУ в кэш не только одну переменную, но и *кэш-линию*. 
Кэш-линия -- это непрерывный сегмент памяти фиксированного размера, обычно 64 байта (8 переменных `int64`). 
Рассмотрим получение блока памяти на примере. МЫ вызываем функцию `Sum` для среза из 16 элементов. Когда `Sum` обращается к `s[0]`, то этот адрес еще не в кэше. Если процессор решит закэшировать эту переменную, то он скопирует весь блок памяти
![[Pasted image 20240928132021.png]]
Сначала обращение `s[0]` приводит к промаху кэша. Это называется принудительным промахом (compulsory miss). Чтение из блока `0x000` далее буду приводить уже к попаданию в кэш.
### Срез структур и структура срезов
Сравним выполнение двух функций. Первая принимает срез структур и суммирует все поля `a`
```go
type Foo struct {
	a, b int64
}

func sumFoo(foos []Foo) int64 {
	var total int64
	for i := 0; i < len(foos); i++ {
		total += foos[i].a
	}
	return total
}
```
Вторая функция принимает структуру, содержащую срезы:
```go
type Bar struct {
	a, b []int64
}

func sumBar(bar Bar) int64 {
	var total int64
	for i := 0; i < len(bar.a); i++ {
		total += bar.a[i]
	}
	return total
}
```
Будет ли какая-то разница в скорости выполнения? Сначала посмотрим на различия в памяти. 
![[Pasted image 20240928132705.png]]
`sumBar` будет быстрее, так как пространственная локализация лучше. Но пространственная локализация не единственная хар-ка, которая помогает процессору.
### Предсказуемость
Предсказуемость - это способность CPU предвидеть следующее действие приложения. Рассмотрим 2 функции. Первая будет суммировать элементы в связном списке
```go
type node struct {
	val int64
	next *node
}

func sumL(n *node) int64 {
	var res int64
	for n != nil {
		res == n.val
		n = n.next
	}
	return res
}
```
И сумму каждого 2 элемента в слайсе
```go
func sum(s []int64) int64 {
	var res itn64
	for i := 0; i < len(s); i+= 2{
		res += s[i]
	}
	return res
}
```
Допустим, что память под связанный список выделяется непрерывно. Рассмотрим на размещение в памяти. Черные прямоугольники - то, что суммируем
![[Pasted image 20240928135410.png]]
У них одинаковая пространственная локализация. Но функция итерирования по слайсу быстрее. 
Чтобы понять это нужно знать про концепцию шагов (striding), относящуюся к тому, как процессор работает с данными. Есть три типа шагов:
- Шаг единичного размера (Unit stride) - все значения, к которым мы хотим получить доступ, располагаются последовательно. Например, срез `[]int64`. Этот шаг предсказуем для процессора и наиболее эффективен, так как требует минимального кэш линий для обхода
- Шаг постоянного размера (Constant stride) - по-прежнему предсказуем для процессора. Например, перебор каждого второго элемента среза. Менее эффективен чем Unit, так как требует большего кол-ва кэш линий
- Неединичный шаг (Non-unit stride) - нельзя предсказать. Например связный список и срез указателей. Так как процессор не знает, выделены ли данные последовательно, он ***не будет загружать кэш-линии***
![[Pasted image 20240928135957.png]]
![[Pasted image 20240928141750.png]]
Результат бенчей. Написал функции для суммирование слайса из 5000 элементов int64, для суммирование слайса из 5000 элементов `*int64`, для суммирование через 2 5000 элементов `int64`
Получилась какая-то хрень... Может я чего-то не понял
```go
package strides_test

import (
    "main/internal/strides"
    "testing"
)

func createArr5000() []int64 {
    res := make([]int64, 0, 5000)
    for i := 0; i < 5000; i++ {
        res = append(res, int64(i))
    }
    return res
}

func createArr5000P() []*int64 {
    res := make([]*int64, 0, 5000)
    for i := 0; i < 5000; i++ {
        n := int64(i)
        res = append(res, &n)
    }
    return res
}
var global int64

func BenchmarkSumArr(b *testing.B) {
    s := createArr5000()
    b.ResetTimer()
    var res int64
    for i := 0; i < b.N; i++ {
        res = strides.Sum(s)
    }
    global = res
}

func BenchmarkSum2Arr(b *testing.B) {
    s := createArr5000()
    b.ResetTimer()
    var res int64
    for i := 0; i < b.N; i++ {
        res = strides.Sum2(s)
    }
    global = res
}

func BenchmarkSumArrP(b *testing.B) {
    s := createArr5000P()
    b.ResetTimer()
    var res int64
    for i := 0; i < b.N; i++ {
        res = strides.SumP(s)
    }
    global = res
}
```

### Стратегия размещения кэша
На сегодняшний день используется наборно-ассоциативный кэш (set-associative cache). Его принцип действия основан на секционировании кэша.
Предположим, что:
- кэш L1D 512 байт (8 кэш линий по 64 байта)
- Матрица состоит из 4 строк и 32 столбцов. Мы читаем только первые 8
Вот так она располагается в памяти
![[Pasted image 20240928142508.png]]
Адрес блока памяти делится на 3 части:
- Смещение блока (block offset, bo) зависит от размера блока. В данном случае размер равен 512 байт - $2^9$. Следовательно, первые 9 бит адреса представляют смещение блока
- Индекс сектора (set index, si) указывает на сектор, к которому относится адрес. Так как кэш является двустороннем секторно-ассоциативным и содержит 8 строк, то имеется всего 8/2=4 сектора. 4 - $2^2$ , поэтому следующие 2 бита представляют индекс сектора
- Остальная часть адреса - биты тегов (tag bits, tb). 
Мы запускаем функцию, которая читает элемент `s[0][0]`, в адресе `все нули`. К кэше его еще нет, поэтому происходит его копирование в нужный раздел
![[Pasted image 20240928143105.png]]
Читая элементы с `s[0][1]` по `s[0][7]` данные берутся из кэша. 
Далее читается `s[1][0]`. В кэше его нет, поэтому копируем
![[Pasted image 20240928143214.png]]
Когда мы начнем читать `s[2][0]`, то мы также копируем. НО. `si` у этого адреса тоже 0. Но нулевой сектор уже занят. CPU заменяет одну из записей в секторе на новую
![[Pasted image 20240928143329.png]]
Политика вытеснения кэша зависит от конкретного CPU, но обычно является псевдо-LRU. Настоящая LRU (Least Recently Used - вытеснение давно не используемых) сложна для обработки. 