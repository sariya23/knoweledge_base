[[Грокаем машинное обучение]]
## Обучение и переобучение
В ML есть концепция недообучения и переобучения. Первый значит, что модель слишком простая и она не может "понять" данные, а переобучение - это когда модель слишком сложная и она просто "запоминает" данные. Оба этих случая плохие. Первый понятно чем плохой. Второй же плох тем, что если мы дадим этой модели новые данные, то она скорее всего будет совершать огромные ошибки, так как она не уловила закономерность, а просто запомнила точка. Это как с экзаменом. Можно вызубрить учебник и ответить на все вопросы из учебника. Но если зададут какой-то вопрос не из учебника, то будет грустно.
![[Pasted image 20250331125957.png]]
> Очень простые модели, как правило, недообучены. Очень сложные модели, как правило, переобучены. 

И вот какую из моделей выберет компьютер? Конечно же 3, так как ошибок там нет. Но это будет неверный выбор, так как модель 3 скорее всего просто запомнила результаты. Нужна какая-то другая метрика выбора модели.
## Тестирование модели
Чтобы понять, подходит модель или нет, нужно ее протестировать. 
> Тестирование модели состоит в выборе небольшого набора точек из набора данных и использовании их не для обучения, а для тестирования эффективности. Такой набор точек называется *тестовым набором*.

Оставшиеся точки используются для обучения. Этот набор называется обучающим. 
Теперь как выбирать
![[Pasted image 20250331130535.png]]
- Первая модель имеет высокую погрешность как в тестировании, так и в обучении. Значит это просто плохая модель.
- Вторая модель имеет небольшую погрешность тестирования. Это хорошая модель
- Третья модель имеет огромные погрешности в тестировании, но при этом хорошо справилась с обучающим набором. Значит эта модель переобучена.
Но тут тоже не все так просто
> ЗОЛОТОЕ ПРАВИЛО: никогда не применять для обучения тестовые данные

Вообще набор надо дробить на 3 части:
- Обучающий набор для обучения всех моделей
- Контрольный набор для принятия решения о том, какую модель использовать
- Тестовый набор для проверки того, насколько хорошо модель справилась.
Тестовый набор мы должны применять в самом конце, чтобы понять, насколько хорошо сработала модель. Дробить это все надо так: 60-20-20 соответственно.

## Регуляризация
### Измерение сложности модели. Нормы L1 и L2
Модель с большим кол-во весов или более высокими весами, как правило, сложнее.
- Сумма абсолютных значений весов - L1
- Сумма квадратов весов - L2
Смещение не включено в эти нормы, так как смещение - это предсказанное значение, если все веса 0.
## Регрессия лассо и гребневая регрессия
Регуляризация применяет такой принцип: нужно чтобы и просто было, и качество хорошее. Для этого есть 2 меры:
- Ошибка регрессии - показатель качества модели. Это могут быть абсолютные или квадратические погрешности
- Слагаемое регуляризации - мера сложности модели. Это может быть норма L1 или L2
Величина, которую мы хотим свести к минимуму - это модифицированная ошибка
```
ошибка = ошибка регрессии + слагаемое регуляризации
```
Если мы обучаем регрессионную модель с помощью L1 - это модель регрессии лассо
Если на L2 - гребневая регрессия 
## Регулирование уровня производительности и сложности
Для поиска золотой середины есть гиперпараметр - параметр регуляризации. Обычно обозначается как лямба.
Теперь ошибка выглядит так:
```
ошибка = ошибка регрессии + λ*слагаемое ругуляризации
```
Обычно берут степени 10: 10, 1, 0.1, 0.01...
## Эффекты регуляризации
- Если мы используем L1, то получим модель с меньшим кол-во весов, то есть некоторые веса станут 0
- Если мы используем L2, то получит модель с меньшими весами.
==Краткое эмпирическое правило: если у нас слишком много признаков и мы хотели бы избавиться от большинства из них, то используем L1. Если функций всего несколько, и мы считаем, что все они релевантны, то используем L2==
![[Pasted image 20250331132754.png]]

