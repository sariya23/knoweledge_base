Нейронная сеть - это несколько перспетронов, выход которых привязан к входу другого персептрона
![[Pasted image 20250406140055.png]]
## Методы обучения
Тут также для борьбы с переобучением используется регуляризация. Но также есть и прореживание. Это вероятность того, что какой-то слой удалится на время одного периода обучения, чтобы он не оказывал слишком большого влияния. 
## Нейронные сети для регрессии
Нейронные сети можно использовать и для регрессии, просто убрав функцию активации на выходном слое
## Пример
![[Pasted image 20250406141712.png]]
Вот у нас есть какие-то значения $x_1$ и $x_2$ и смещение 1. Функцией активации служит сигмоида. Получается, чтобы посчитать прогноз для точки (1, 1):
$$
l_1=\sigma(1*1-2*1-1*1)=\sigma(-2)=0.12
$$
$$
l_2=\sigma(-1*1+3*1-1*1)=\sigma(1)=0.731
$$
$$
\hat{y}=\sigma(0.12*-1+2*0.731+1*1)=\sigma(2.342)=0.91
$$

## Резюме
- Нейронные сети состоят из наборов перспептронов, где выходные данные одного слоя служат входным сигналом другого
- Основной строительный блок нейронной сети - персептрон. Он получает несколько значений в качестве входных данных и выдает одно значение, вычисляемое умножением входных данных на веса, добавлением смещения и применения функции активации
- Популярные функции активации: сигмоидная, гиперболический тангенс, softmax и блок линейной ретификации
- Сигмоидная функция - это функция, которая превращает любой действительное число в число между 0 и 1
- Гиперболический тангенс работает аналогично, только превращает в диапазон чисел от -1 до 1
- Эти функции используются в основном для конечного слоя
- Функция ReLU - это функция, которая обращает отрицательные значения в 0, а положительные оставляет без изменения. Она используется чаще, так как убирает проблему исчезающего градиента
