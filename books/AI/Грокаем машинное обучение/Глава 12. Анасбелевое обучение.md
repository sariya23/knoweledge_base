В общем в ансамблеевом обучении мы объединяем простые модели в более сложные. Например, строим 5 простых деревьев решений, а потом объединяем в одно общее. Для объединения есть несколько техник
- **Бэггинг**: создание случайных наборов путем выборки случайных точек из этого набора. Разные модели обучаются на разных частях общего набора. Затем слабые алгоритмы объединяются в один сильный путем голосования или усреднения значений
- **Бустинг**: строим первый слабый алгоритм, а затем увеличиваем веса точек, которые были классифицированы неверно. Далее строим второй обучающий алгоритм, который уже уделяет большее внимание неправильно классифицированным точкам. 
Популярные ансамблевые алгоритмы:
- Random Forest (бэггинг)
- AdaBoost (бустинг)
- Градиентный бустинг (бустинг)
- XGBoost (бустинг)

