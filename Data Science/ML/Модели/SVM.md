## Гиперпараметры
`C` - настройка уровня регуляризации. Чем больше, тем сильнее веса у модели и значит, она с большей вероятностью переобучится 
`gamma` - также влияет на недообучение и переобучение. Если слишком мал, то границы разделений будут широкие (недообучение), а если слишком велик, то узкие (переобучение)

## Сводка
SVM - это алгоритм обучения с учителем. Используется для классификации. Он может применять как для данных, которые можно разделить линией, так и для данных, которые нельзя разделить линией. Для того, чтобы модель делала хорошие прогнозы, надо правильно подбирать параметры

## Обучение линейной модели в scikit-learn
```python
svm = SVC(kernel="linear", C=1.0, random_state=1)
svm.fit(features_train_std, labels_train)
```
## Ядерный SVM
Вот такие данные мы не сможем разделить линейной гиперплоскостью с помощью логистической регрессии или линейного SVM
![[newplot (3).png]]
Для того чтобы разделить нелинейные данные нужно применять ядерные методы в SVM
### Обучение в scikit-learn
```python
svm = SVC(kernel="rbf", random_state=1, gamma=0.01, C=1.0)
svm.fit(features_train_std, labels_train)
```
