Все, что было описано выше, можно выполнять не вручную, а используя такую штуку как конвейер Pipeline.
```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline

features = df.iloc[:, 2:].values
labels = df.iloc[:, 0].values

# Кодирование меток
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Разбиение набора
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, stratify=labels, test_size=0.2)

pipe_logistic_regression = make_pipeline(StandardScaler(), PCA(n_components=2), LogisticRegression())
pipe_logistic_regression.fit(features_train, labels_train)
labels_pred = pipe_logistic_regression.predict(features_test)
acc = pipe_logistic_regression.score(features_test, labels_test)
```
Через функцию `make_pipeline` мы создаем последовательность действий, которые должны выполниться. Их кол-во не ограничено. При вызове метода `fit` данные передаются по цепочке
```
X -> StandartScaler().fit_transform() -> PCA(2).fit_transform() -> LogisticRegression
```
Пайплайн принимает неограниченное кол-во объектов, реализующих методы `fit` и `transform`, а последним оцениватель, у которого есть методы `fit` и `predict`
![[Pasted image 20250411232400.png]]
Если же мы используем K-fold для разбиения данных, то нам нужно передать этот пайп как параметр `estimator`
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(estimator=pipeline, X=features_train,
y=labels_train, cv=10, n_jobs=n)
```
В `scores` будет лежать массив оценок.