[[Airflow]]
## Основные компоненты
- DAGs (папка с дагами) - директория, где хранятся даги
- База метаданых - в БД хранится информация о запущенных задачах, их состоянии и другой мета инфы, связанной с выполнением задач
- Web UI - админка
- Scheduler - планировщик, который проверяет и обновляет даги, следит за расписанием задач и запускает их (а точнее его встроенный компонент Executor)
## Процесс запуска DAG
- Scheduler сканирует папку с дагами, чтобы выяснить кого когда запускать. Если будет найдена ошибка, то она отобразится в UI. Там отображаются ошибки только связанные с синтаксисом Airflow. Файлы, расположенные вне папки с дагами не воспринимаются airflow
- После того, как Scheduler решит, что время дага настало, executor добавляет задачу в очередь на выполнение
- Далее включается Worker. Он вытаскивает задачу из очереди и начинает выполнение
- ![[Pasted image 20250808162712.png]]
## Executors и Pools
Executor - модуль Scheduler, который отвечает за то, каким образом задачи будут доставляться до воркеров, а также за степень распределенности системы. 
Основные виды Executor:
- `Sequential`
- `Local`
- `Celery`
- `Kubernetess`
### Sequential
Самый простой Executor. Используется как executor по умолчанию. На этом executor нельзя выполнять задачи параллельно. По сути этот исполнитель - цикл по задачам. Он является и воркером
### Local
В этом экзекьюторе уже используется только клиент серверная БД. Задачи выполняются на одном компьютере, могут выполнятся параллельно, в разных процессах. Поэтому и нельзя передавать данные между операторами. 
При работе с таким экзекьютором уже нужны пулы, так как кол-во процессов может расти бесконечно.
Пулы можно создавать через админку и передавать его в операторы
```python
task_1= BashOperator(
    task_id='task_1',
    pool='non_default_pool',
    bash_command="sleep 10",
    dag=dag,
)
```
Где `pool` - название пула. По дефолту у него 128 слотов. При работе с пулом порядок параллельных задач не определен. Поэтому задач можно ставить веса, чтобы повышать их приоритет
```python
task_10 = BashOperator(
    task_id='task_10',
    pool='non_default_pool',
    priority_weight=5
    bash_command="sleep 10",
    dag=dag,
)
```
### Celery и Kuber
Эти экзекьюторы нужны для прода, они позволяют создать один мастер узел, который будет распределять задачи по разным воркер нодам