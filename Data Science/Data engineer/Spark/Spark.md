[[Spark]]
Spark - это фреймворк для распределенного анализа данных. Он появился как альтернатива хадупу с точки зрения удобства и производительности. 
Основная концепция - RDD. Она позволяет хранить данные в ОЗУ, что ускоряет обработку
**Основные ядра**:
- Spark Core - основное ядро спарка. Предоставляет API, менеджит память, управляет stdin/out
- SparkSQL - ядро для поддержки работы с данными через SQL. Есть интеграция с HIVE
- SparkStreaming - ядро для обработки данных в реальном времени
- MLlib - библиотека для машинного обучения
- GraphX - библиотека для работы с графами
- SparkR - пакет для работы через язык R

## Архитектура спарка
- Driver (мастер)
	- Это то, на чем запускается код
	- Разбивает задачи и отдает их executors
	- Следит за выполнением
	- Собирает результат
- Executors
	- Это процессы, на которых выполняются какие-то задачи в кластере. Их может быть несколько
	- Именно они выполняют задачи от Driver
	- Хранят данные в памяти или на диске
## Как спарк обрабатывает код
- Сначала строится DAG (ациклический направленный граф). То есть сразу выполнения кода не происходит - сначала строится план, как его выполнять
- Спарк - ленивый, поэтому производит вычисления, только в action методах (collect, count, save и тд). То есть даже если мы напишем какой-то запрос, то выполнится он только после действия
- У спрака есть встроенный оптимизитор запросов - catalyst. Он строит оптимальный sql-like запрос для каждой задачи
- Также спарк кэширует данные в оперативную память. Особенно промежуточные. Но есть такая вещь как disk spill - это когда данные не помещяются в оперативку и кладутся на диск, чтобы избежать падения по OOM