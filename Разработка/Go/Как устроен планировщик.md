[[Go]]
## Требования к планировщику
- Должны задействоваться все ядра, чтобы ничего не простаивало
- Простота. Запустить асинхронно функцию должно быть просто
- Легковесность. Работа и создание горутин должно быть дешевой операцией
## Ликбез по планировщику ОС
Предположим у нас есть один процессор, у него есть один слот для выполнения задачи и у него есть очередь, где будут скапливаться задачи для дальнейшего выполнения
Решать, какая задача будет выполняться, а какие подождут, будет планировщик ОС. Планировщик ОС управляет тредами
![[Pasted image 20250308115102.png]]
Тред - это работа, которая выполняется на процессоре. Тредов может быть много. Тред может быть в 3 состояниях:
- Executing - тред, который уже выполняется на ядре
- Runnable - тред, который готов к выполнению, но ждет своей очереди
- Waiting - тред, который чего-то ждет. Например I/O
Планировщик в какие-то моменты времени может переключать треды. То есть снимать тред с Executing и ставить на выполнение тред из очереди. То есть переключать контекст - context switching. Это не дешевая операция. Также мы как разработчики не можем никак узнать как планировщик ОС будет переключать контексты. 
**Треды - это дорого**. Они потребляют больше памяти, чем горутины. И также чем у нас больше тредов, тем больше переключения контекста, а поэтому может быть такое, что полезной работы будет меньше, чем работы на переключение контекста.
## Концепция горутин
Горутины выполняются на тредах и также имеют 3 состояние:
- Executing
- Runnable
- Waiting
Горутинами уже управляет планировщик Go. 
## GMP-модель
- G - goroutines
- M - machine. То есть то, на чем выполняются горутины
- P - processor. Некая сущность, которая помещает на machine горутины и убирает. Он ничего не планирует
## Модель планировщика
### Модель 1:1
В такой модели на каждую горутину создается новый тред. То есть если Processor берет горутину, то создает под нее тред. Когда горутина отработала тред удаляется.
Такое решение подходит, так как мы получаем конкурентность и задействуем все ядра процессора, потому что планировщик ОС не даст тредам простаивать
### Модель 1:N'
Один тред - несколько горутин. Но такое нам не подходит, так как он лишает нас параллельности. 
### Пул тредов
В модели 1:1 нас кое-что не устраивает - создание и удаление тредов не дешевая операция. Сделаем так, чтобы при завершении горутины тред не удалялся, а куда-то складывался. И в этом месте (пул тредов) будут лежать свободные треды. И когда появится новая горутина мы посмотрим есть ли в пуле тредов свободные, что захватить их
### Ограниченный пул тредов
Но нас такое не очень устраивает. Как было написано выше: чем больше тредов, тем больше свитчинга контектса. Да и сами треды потребляют относительно много памяти.
Чтобы решить эту проблему, мы можем ограничить кол-во тредов, которые мы можем создавать.
### GRQ - global run queue
Поведение остается примерно таким же. Если в пуле тредов есть свободные, то горутина его забирает, если нет, то проверяем пул тредов и если лимит не превышен, то создаем тред. А вот если лимит превышен, то текущая горутина должна ожидать, пока другая горутина освободит тред. 
![[Диаграмма без названия (1).jpg]]
У нас появляется концепция ждущих горутин. Мы будем помещать их GRQ - global run queue. Это очередь по принципу FIFO (там есть какой-то слот по LIFO, но там дебри какие-то)
### Сколько тредов использовать?
Если у нас есть 3 ядра и мы ограничим пул 2мя тредами, то получается 1 тред будет простаивать. Если мы сделаем так, что тредов будет больше чем процессов, то треды будут простаивать. Поэтмоу пул тредов нужно ограничить кол-ом ядер. 
### Конкурентный доступ в GRQ (модель M:N)
Так как тредов у нас несколько, то и Processor нам нужно тоже несколько. И тогда появляется проблема, что GRQ одна, а Processor несколько. И может быть такое, что оба Processor могут попытаться захватить одну и ту же горутину из GRQ. 
Эту проблему можно решить мьютексом. Когда Processor лезет в GRQ, то он сначала запрашивает разрешение - не пользуется GRQ кто-то другой? Если нет, то он сам просит заблочить GRQ и берет горутину, а потом отпускает мьютекс. 
И теперь у нас модель M:N - кол-во тредов и кол-во горутин не зависят друг от друга. 
### LRQ - local run queue
У нас все еще есть проблемы. Из-за того, что мы используем mutex на GRQ, то все будет работать не очень быстро. Поэтому можно выдать каждому процессору его локальную очередь, доступ к которой будет иметь только он
![[Pasted image 20250309113332.png]]
Но глобальная очередь все еще остается. Мы в нее будем все равно заглядывать. Раз в 61 раз. То есть процессор сначала ищет в LRQ, если не нашел берет из GRQ. А если LRQ очень быстро заполняется, то раз в 61 раз мы будем смотреть в GRQ, чтобы горутины там не простаивали.
### Ждущие горутины
Горутинами в состоянии Wating управляет уже другая сущность. Это сделано через каналы. В структуре канала есть та самая wait queue [[Как устроены каналы]]. 
### Work stealing
У нас может возникнуть ситуация, что  один процессор простаивает. Эта проблема решается тем, что процессор идет к товарищу и тырит горутины. И не одну, а половину горутин в локальной очереди. Это сделано, чтобы он туда поменьше ходил. И теперь у нас появилось еще одно место, где нужно проверять горутины
- 1/61: GRQ
- LRQ
- Work stealing
- GRQ
### Блокирующие вызовы (syscall) (N:P:M модель)
В случае, когда горутина совершает syscall блокируется не только сама горутина и весь поток системы. Нас такая ситуация не устраивает, так как тогда получается простой.
Мы можем создать новый тред, отвязать Processor от заблокированного треда и привязать к новосозданному. Такой механизм называется handoff.
Но щас есть некоторая проблема, получается, что каждый сискол будет создавать новый тред. Но не все сисколы длинные. Иногда выгоднее чуть подождать, чем создавать новый тред. За этим следит sysmon, он замеряет время вызова сискола и если оно больше 10мс, то выполняется handoff. Сисмон выполняется на отдельном служебном треде. 
Когда сискол выполнился горутина переходит из состояния waiting в runnable. И мы возвращаем ее либо в тот же процессор, откуда забрали, если он не занят, либо помещаем ее в GRQ
И теперь получается, что у нас модель из N:M перешла в N:P:M, так как у нас появились спящие треды и системный тред. 
### Асинхронное выполнение сисколов без создание нового треда
Сисколы неизбежно блокируют поток на системном уровне. Но системы предоставляют инструменты для асинхронного выполнения этих сисколов. В линуксе это epoll. Вместо того, чтобы блокировать тред он просто отдает epoll этот сискол и периодически опрашивает его о состоянии сискола. Но не все сисколы можно выполнять асинхронно. Нельзя делегировать на epoll работу с файловой системой. А пот работу с сетью - можно.
### Network-poller
В планировщике есть сущность netpoller, которая принимает горутины, совершившие долгий сискол. И тред становится свободным для выполнения других горутин. 
Теперь процессор ищет горутины еще и в netpoller, но в самую последнюю очередь:
- 1/61: GRQ
- LRQ
- Work stealing
- GRQ 
- netpoller
Но что будет, если очереди процессоров очень быстро поплняются и дело не доходит до netpoller? Эту проблему решает сисмон. Если в течении 10мс никто не опросил netpoller, то сисмон сам помещает runnnable горутины в GRQ. 
### Какая многозадачность в GO?
До версии 1.14 планировщик был кооперативным. 
В каком порядке вообще выполняются горутины? Они идут по очереди. Но что если какая-то горутина выполняется слишком долго? Слишком долго это сколько и кто будет за этим следить? Следить за этим будем тот же самый сисмон, а слишком долго это те же 10мс. Но он не резко завершает горутину. Он может только поставить ей флаг `stackguard` в значение `stackPreempt`. Если он поставил это значение, то горутине пора стать runnable. Но когда горутина уйдет, нужно подобрать какое-то безопасное место, чтобы в этом момент не было модификации памяти. Горутина проверяет этот флаг в:
- Прологе (вызов другой функии)
- Во время блокирующей операции
Но тут есть проблемка:
```go
func main() {
	// Чтобы был один тред
	runtime.GOMAXPRCOS(1)
	go func() {
		sum := 0
		for {
			sum++
		}
	}()
	time.Sleep(time.Second)
}
```
Тут горутина не совершает никаких действий, чтобы проверить флаг `stackguard`. Если запустить на версии до 1.14, то все зависнет.
Как решать?
Нужно послать какой-то ОС сигнал. Если горутина выполняется дольше 10мс, то посылается сигнал SIGURG (так как он используется очень редко)
В Го многозадачность кооперативная с элементами вытеснения.
## Проверяем на практике
### Что происходит после запуска
Первым делом инициализируется пакет `runtime`, далее пакет инициализирует P для обработки горутин.
Чтобы узнать сколько у нас логических ядер нужно вызвать функцию `runtime.NumCPU`
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumCPU()) // 12
}

```
Так как тредов у нас столько же сколько и ядер, то их 12. Чтобы это проверить нужно вызвать функцию `runtime.GOMAXPROCS(0)`, если n<1, то возвращается текущее значение
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumCPU()) // 12
	fmt.Println(runtime.GOMAXPROCS(0)) // 12
}
```
А что если передать туда другое число?
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumCPU()) // 12
	fmt.Println(runtime.GOMAXPROCS(2)) // 12
}

```
Почему-то кол-во не изменилось. Эта функция сначала возвращает кол-во, которое есть на данный момент, а только потом уже модифицирует. То есть если вызвать ее еще раз, то получим 2
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumCPU())      // 12
	fmt.Println(runtime.GOMAXPROCS(2)) // 12
	fmt.Println(runtime.GOMAXPROCS(0)) // 2
}
```
### Трейсинг планировщика
Чтобы посмотреть трейсинг планировщика нужно сбилдлить программу и выполнить ее с переменной окружения `GODEBUG=schedtrace=1000`, где 1000 кол-во милисекунд, через которые будет выводится информация
```shell
GODEBUG=schedtrace=1000 ./sched 
```
На такой программе
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumCPU())      // 12
	fmt.Println(runtime.GOMAXPROCS(2)) // 12
	fmt.Println(runtime.GOMAXPROCS(0)) // 2
}
```
Получаем такой результат
![[Pasted image 20250309143331.png]]
- `gomaxprocs` кол-во процессоров. Так как это инициализация, то программа не дошла еще до момента, где мы установили их на 2
- `idleprocs` кол-во простаивающих процессоров
- `threads` кол-во тредов программы. Помним, что один тред выделяется для сисмона
- `idlethreads` кол-во простаивающих тредов
- `runqueue` кол-во горутин в GRQ
- Список ноликов - это кол-во горутин в LRQ каждого процессора
### Как узнать кол-во горутин
Для этого используется функция `runtime.NumGoroutine()`
```go
package main

import (
	"fmt"
	"runtime"
)

func main() {
	fmt.Println(runtime.NumGoroutine()) // 1
}
```
### Выполнение коротких сисколов
Программа:
```go
func main() {
	go func() {
		for {
			time.Sleep(time.Second)
		}
	}()
	fmt.Println(runtime.NumGoroutine()) // 2
	time.Sleep(time.Minute)
}
```
`fmt.Println` совершает короткий сискол, так как выводит что-то в stdout
