[[Go]]
## Отсутствие синхронизации
```go
// print square of range 0..20
func main() {
    counter := 20
    for i := 0; i < counter; i++ {
        go func() {
            fmt.Println(i * i)
        }()
    }
    time.Sleep(time.Second)
}
```
Мы не можем гарантировать, что горутины завершаться за 1 секунду. Тут правильно будет использовать `WaitGroup`
```go
func main() {
    counter := 20
    var wg sync.WaitGroup
    for i := 0; i < counter; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            fmt.Println(i * i)
        }()
    }
    wg.Wait()
}
```

## Мапы
### Запись в мапу
```go
func main() {
    storage := make(map[int]int, 1000)
    var wg sync.WaitGroup
    writes := 1000
    wg.Add(writes)
    for i := 0; i < writes; i++ {
        go func() {
            defer wg.Done()
            storage[i] = i
        }()
    }
    wg.Wait()
    fmt.Println(storage)
}
```
Здесь будет `fatal error: concurent map writes`. Под капотом мапа пересоздается, данные эвакуируются - в общем при конкурентности у компилятора закипает мозг и получается `fatal error`. Нужно поместить запись в критическую секцию
```go
    storage := make(map[int]int, 1000)
    var wg sync.WaitGroup
    var mu sync.Mutex
    writes := 1000
    wg.Add(writes)
    for i := 0; i < writes; i++ {
        go func() {
            defer wg.Done()
            mu.Lock()
            defer mu.Unlock()
            storage[i] = i
        }()
    }
    wg.Wait()
    fmt.Println(storage)
```

### Запись и чтение в мапе
```go
func main() {
    storage := make(map[int]int, 1000)
    var wg sync.WaitGroup
    var mu sync.Mutex
    reads, writes := 1000, 1000
    wg.Add(writes)
    for i := 0; i < writes; i++ {
        go func() {
            defer wg.Done()
            mu.Lock()
            defer mu.Unlock()
            storage[i] = i
        }()
    }
    wg.Add(reads)
    for i := 0; i < reads; i++ {
        go func() {
            defer wg.Done()
            _, _ = storage[i]
        }()
    }
    wg.Wait()
    fmt.Println(storage)
}
```
Здесь возникает гонка данных - горутина на чтение может читать тот ключ, в который сейчас пишет горутина-писатель.
Операция чтения cuncurency safe, поэтому можно втыкнуть не обычный мютекс, а мютекс на чтение
```go
func main() {
    storage := make(map[int]int, 1000)
    var wg sync.WaitGroup
    var mu sync.RWMutex
    reads, writes := 1000, 1000
    wg.Add(writes)
    for i := 0; i < writes; i++ {
        go func() {
            defer wg.Done()
            mu.Lock()
            defer mu.Unlock()
            storage[i] = i
        }()
    }
    wg.Add(reads)
    for i := 0; i < reads; i++ {
        go func() {
            defer wg.Done()
            mu.RLock()
            defer mu.RUnlock()
            _, _ = storage[i]
        }()
    }
    wg.Wait()
    fmt.Println(storage)
}
```
Также можно использовать `sync.Map` - читать и писать потокобезопасно и не надо прописывать мютексты. Но у нее есть недостатки:
- Нет типизации
- Нельзя взять длину
- В некоторых ситуациях она медленнее, чем мапа + мютекс
В общем надо 100 раз подумать.
### Запись и чтение в мапу v2
Более завуалированный пример
```go
func main() {
    storage := make(map[int]struct{})
    var mu sync.Mutex
    capacity := 1000
    doubles := make([]int, 0, capacity)
    for i := 0; i < capacity; i++ {
        doubles = append(doubles, rand.Intn(10))
    }
    uniqIDs := make(chan int, capacity)
    for i := 0; i < capacity; i++ {
        go func() {
            if _, ok := storage[doubles[i]]; !ok {
                mu.Lock()
                storage[doubles[i]] = struct{}{}
                mu.Unlock()
                uniqIDs <- doubles[i]
            }
        }()
    }
    fmt.Println(uniqIDs)
}
```
Тут мапа представляет множество. Мы сначала генерируем 1000 случайных чисел, а потом в мапе сохраняем только уникальные.
Тут 2 проблемы:
- Нет синхронизации горутин
- Происходит одновременное чтение и запись в мапу 
Чтение происходит в условии. Можно поместить весь `if` в критическую секцию. Ну и вейт группу добавить
```go
func main() {
    storage := make(map[int]struct{})
    var mu sync.Mutex
    capacity := 1000
    doubles := make([]int, 0, capacity)
    for i := 0; i < capacity; i++ {
        doubles = append(doubles, rand.Intn(10))
    }
    uniqIDs := make(chan int, capacity)
    var wg sync.WaitGroup
    for i := 0; i < capacity; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            mu.Lock()
            defer mu.Unlock()
            if _, ok := storage[doubles[i]]; !ok {
                storage[doubles[i]] = struct{}{}
                uniqIDs <- doubles[i]
            }
        }()
    }
    wg.Wait()
    fmt.Println(uniqIDs)
}
```

## Каналы
### Чтение из небуферезированного канала и пустой `select`
```go
func main() {
    ch := make(chan int)
    <-ch // deadlock
}

func main1() {
    select {} // deadlock
}
```
Планировщик смотрит, пишет ли кто-то еще в этот канал. Нет - значит дедлок. Кол-во активных горутин можно получить через `runtime.NumOfGoroutine`
Пустой `select` тоже дедлок. Но раньше, вроде до 1.18 там было подвисание

### Таймаут для асинхронных вызовов
```go
func main() {
    chanForResponse := make(chan int)
    go RPCCall(chanForResponse)
    res := <-chanForResponse
    fmt.Println(res)
}

func RPCCall(ch chan<- int) {
    time.Sleep(time.Hour)
    ch <- rand.Int()
}
```
Здесь мы будет ждать час, пока что-то запишется в канал. Нам нужно как-то сделать таймаут. Если мы ждем больше n-секунд, то отменяем вызов. Это можно сделать с помощью контекста или `time.After`
Контекст:
```go
func main() {
    ctx, cancel := context.WithTimeout(context.Background(), time.Second)
    defer cancel()
    chanForResponse := make(chan int)
    go RPCCall(chanForResponse)
    select {
    case val := <-chanForResponse:
        fmt.Println(val)
    case <-ctx.Done():
        fmt.Println("timeout")
    }
}
```
Мы вызываем отложено `cancel`, чтобы гарантировать отчистку ресурсов, если контекст не отменился по таймауту. В `select` мы ждем либо ответ от вызова, либо истечение тайм аута. 

Через `time.After`
```go
func main() {
    chanForResponse := make(chan int)
    go RPCCall(chanForResponse)
    select {
    case val := <-chanForResponse:
        fmt.Println(val)
    // Так лучше не делать. Так как возвращается канал, который не закрывается
    case <-time.After(time.Second):
        fmt.Println("canclled")
    }
}
```
Логика та же, но так лучше не делать. Так как `time.After` создает временные ресурсы, которые могут отчиститься не сразу. И это не идиоматическое решение. Задача на таймаут - контекст!

### `default` в `select`
```go
func main() {
    ch := make(chan int)
    select {
    case val := <-ch:
        fmt.Println(val)
    }
}
```
Здесь мы блокируемся. Нужно как-то предвидеть эту блокировку. Для этого есть ветка `default`
```go
func main() {
    ch := make(chan int)
    select {
    case val := <-ch:
        fmt.Println(val)
    default:
        fmt.Println("nobody write in chan")
    }
}
```
### Merge channels
Ну тут паттерн Fan in
```go
func main() {
    ch1 := make(chan int, 10)
    ch2 := make(chan int, 20)

    ch1 <- 1
    ch2 <- 2
    ch2 <- 4
    for val := range merge(ch1, ch2) {
        fmt.Println(val)
    }
}

func merge[T any](chns ...chan T) chan T {
    ch := make(chan T)
    close(ch)
    return ch
}
```
Вот решение
```go
func main() {
    ch1 := make(chan int, 10)
    ch2 := make(chan int, 20)
    ch1 <- 1
    ch2 <- 2
    ch2 <- 4
    close(ch1)
    close(ch2)
    for val := range merge(ch1, ch2) {
        fmt.Println(val)
    }
}

func merge[T any](chns ...chan T) chan T {
    res := make(chan T)
    var wg sync.WaitGroup
    output := func(ch <-chan T) {
        for n := range ch {
            res <- n
        }
        wg.Done()
    }
    for _, ch := range chns {
        wg.Add(1)
        go output(ch)
    }
    go func() {
        wg.Wait()
        close(res)
    }()
    return res
}
```
Каналы только важно закрыть, а иначе дедлок будет.

### Превращение синхронного кода в pipeline
Есть такой код:
```go
type Job struct {
    Value int64
    State State
}

type State int

const (
    InitState State = iota
    FirstStage
    SecondStage
    FinishedStage
)

func main() {
    length := 50_000_000
    jobs := make([]Job, length)
    for i := 0; i < length; i++ {
        jobs[i].Value = int64(i)
    }
    start := time.Now()
    jobs = LastProcessing(SecondProcessing(FirstProcessing(jobs)))
    finish := time.Since(start)
    fmt.Println(finish)
}

func FirstProcessing(jobs []Job) []Job {
    var result []Job
    for _, job := range jobs {
        job.Value = int64(float64(job.Value) * math.Pi)
        job.State = FirstStage
        result = append(result, job)
    }
    return result
}

func SecondProcessing(jobs []Job) []Job {
    var result []Job
    for _, job := range jobs {
        job.Value = int64(float64(job.Value) * math.E)
        job.State = SecondStage
        result = append(result, job)
    }
    return result
}

func LastProcessing(jobs []Job) []Job {
    var result []Job
    for _, job := range jobs {
        job.Value = int64(float64(job.Value) / float64(rand.Intn(10)))
        job.State = FinishedStage
        result = append(result, job)
    }
    return result
}
```
Он последовательно обрабатывает 50_000_000 значений. Но все значения сразу нам не нужны, нужно как-то создавать стриминговую выдачу данных. Тут поможет паттерн pipeline
```go
type Job struct {
    Value int64
    State State
}

type State int

const (
    InitState State = iota
    FirstStage
    SecondStage
    FinishedStage
)

func main() {
    start := time.Now()
    in := build(50_000_000)
    p1 := task1(in)
    p2 := task2(p1)
    res := task3(p2)
    _ = res
    finish := time.Since(start)
    fmt.Println(finish)
}

func build(iter int) <-chan Job {
    out := make(chan Job)
    go func() {
        for i := 0; i < iter; i++ {
            out <- Job{Value: int64(i)}
        }
        close(out)
    }()
    return out
}

func firstLogic(j *Job) {
    j.Value = int64(float64(j.Value) * math.Pi)
    j.State = FirstStage
}

func secondLogic(j *Job) {
    j.Value = int64(float64(j.Value) * math.E)
    j.State = SecondStage
}

func finishLogic(j *Job) {
    j.Value = int64(float64(j.Value) / float64(rand.Intn(10)))
    j.State = FirstStage
}

func task1(in <-chan Job) <-chan Job {
    out := make(chan Job)
    go func() {
        for task := range in {
            firstLogic(&task)
            out <- task
        }
        close(out)
    }()
    return out
}

func task2(in <-chan Job) <-chan Job {
    out := make(chan Job)
    go func() {
        for task := range in {
            secondLogic(&task)
            out <- task
        }
        close(out)
    }()
    return out
}

func task3(in <-chan Job) <-chan Job {
    out := make(chan Job)
    go func() {
        for task := range in {
            finishLogic(&task)
            out <- task
        }
        close(out)
    }()
    return out
}
```

### Rate limiter
```go
func main() {
    count := 1000
    ch := make(chan int, count)
    var wg sync.WaitGroup
    for i := 0; i < count; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            ch <- RCPCall()
        }()
    }
    wg.Wait()
    close(ch)
    for v := range ch {
        fmt.Println(v)
    }
}

func RCPCall() int {
    return rand.Int()
}
```
Есть такой код, который параллельно отправляет 1000 запросов. Но нам говорят, что можно отправлять 10 запросов в секунду. Нужно как-то ограничить.
```go
func main() {
    count := 1000
    ch := make(chan int, count)
    limiter := make(chan struct{}, 10)
    go func() {
        t := time.NewTicker(time.Second)
        for {
            <-t.C
            for i := 0; i < 10; i++ {
                limiter <- struct{}{}
            }
        }
    }()
    var wg sync.WaitGroup
    for i := 0; i < count; i++ {
        wg.Add(1)
        go func() {
            <-limiter
            defer wg.Done()
            ch <- RCPCall()
        }()
    }
    wg.Add(1)
    go func() {
        
        defer wg.Done()
        for i := 0; i < count; i++ {
            fmt.Println(<-ch)
        }
    }()
    wg.Wait()
}

func RCPCall() int {
    return rand.Int()
}
```
Но это не продовский код, так как есть готовые библиотеки