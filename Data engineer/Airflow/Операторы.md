[[Airflow]]
Операторы помещаются в задачи и выполняются конкретные действия. Значения, которые возвращаются из оператора нельзя получить в другом операторе. Для этого нужны внешние носители - БД, диск или сеть
## DummyOperator
Это просто заглушка. Он ничего не делает
```python
from airflow import DAG
from datetime import timedelta
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator
 
dag =  DAG('dag', schedule_interval=timedelta(days=1), start_date=days_ago(1))

t1 = DummyOperator(task_id='task_1', dag=dag)
```
## PythonOperator
Оператор для выполнения Python кода
```python
from airflow.operators.python import PythonOperator

task_extract = PythonOperator(
    task_id='extract_data',         
    python_callable=extract_data,    
    op_args=['http://www.cbr.ru/scripts/XML_daily.asp', '01/01/2022', './extracted_data.xml'],
    dag=dag,                         
)
```
`task_id` - уникальное имя задачи
`python_callable` - функция для вызова
`op_args` - список позиционных параметров, которые передадутся в функцию
`dag` - передаем инстанс дага, чтобы связать с ним задачу
Также можно передать параметры по имени
```python
task_transform = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    op_kwargs = {
        's_file': './extracted_data.xml', 
        'csv_file': './transformed_data.csv', 
        'date': '01/01/2022'},
    dag=dag,
)
```
## BashOperator
Оператор для выполнения баш команд или запуска баш скрипта
```python
from airflow import DAG
from datetime import timedelta
from airflow.utils.dates import days_ago
from airflow.operators.bash import BashOperator

dag =  DAG('dag', schedule_interval=timedelta(days=1), start_date=days_ago(1))

t1 = BashOperator(task_id='task_1',
                  bash_command='cat /root/airflow/dags/dag.py',
                  dag=dag)
```
## PythonVirtualenvOperator
Этот оператор выполняет ту же цель что и PythonOperator, только он позволяет создать временное виртуальное окружение, скачать туда только на время выполнения библиотеку и использовать ее в этом операторе. Виртуальное окружение создается поверх существующего, поэтому уже установленные библиотеки останутся доступны
```python
from airflow import DAG
from datetime import timedelta, datetime
from airflow.utils.dates import days_ago
from airflow.operators.python_operator import PythonVirtualenvOperator

dag =  DAG('dag', 
            start_date=datetime(2024, 1, 1),
            schedule_interval=None)

def print_context():
    import pycountry # Импорты нужно прописывать в самой функции
    country = list(pycountry.countries)[0]
    print(country)

run_this = PythonVirtualenvOperator(
    task_id='print_the_context',
    python_callable=print_context,
    dag=dag,
    
    requirements=["pycountry==24.6.1"]
)
```
## SimpleHttpOperator
Этот оператор позволяет отравлять http запросы. 
```python
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.http_operator import SimpleHttpOperator

dag = DAG('dag',schedule_interval=None, start_date=days_ago(1))

t1 = SimpleHttpOperator(
    task_id='get',
    method='GET',
    http_conn_id='http_default', # Мы указываем URL в Connection
    endpoint='all', # Прописываем endpoint, то есть метод API
    dag=dag)
```
Этот оператор полезен, не чтобы получить данные, а чтобы отправить запрос. Например авторизация или создание чего-либо
## ClickHouseOperator
Также как и все SQL операторы этот оператор нужен для выполнения SQL запросов. 
```python
from airflow import DAG
from airflow_clickhouse_plugin.operators.clickhouse import ClickHouseOperator
from datetime import datetime

# Создаем DAG
dag = DAG(
    '0_Examples_5_2_4_clickhouseoperator_context',
    schedule_interval='@daily',  # Запускать вручную
    start_date=datetime(2024, 1, 1),
    end_date=datetime(2024, 1, 3),
    tags=['examples']
)

# SQL-запрос, который мы будем выполнять
sql_query = """
    CREATE VIEW currency_view_{{ds_nodash}} as select * from currency_data where date = '{{ ds }}'
"""

# Оператор для выполнения запроса
create_view = ClickHouseOperator(
    task_id='create_view',
    sql=sql_query,  # SQL запрос, который нужно выполнить
    clickhouse_conn_id='clickhouse_default',  # ID подключения, настроенное в Airflow
    dag=dag,
)
```
Внутри запроса можно использовать макросы. Макрос `{{ ds }}` обернут в одинарные кавычки, так как клик требует, чтобы даты были в кавычках