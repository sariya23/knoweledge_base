[[Spark]]
В PySpark есть сессия и есть контекст. Сессия - более предпочтительный способ подключения, так как он включает еще и другие ядра спарка - sql, hive, mllib и тд
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("FirstSparkApp").getOrCreate()
```
При создании сессии можно указать много параметров:
- `builder.appName` - создать имя приложения
- `builder.master` - указать кластер для выполнения
И другие. Большинство параметров задается через конфиг. Дока - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/spark_session.html